{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python376jvsc74a57bd0e3e4e3f8d1004f0635b3e366db2cf4bb93ba9a4575d200ce7de035ae015269d7",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "e3e4e3f8d1004f0635b3e366db2cf4bb93ba9a4575d200ce7de035ae015269d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import movie_reviews \n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.classify.util import accuracy as nltk_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features from the input list of words\n",
    "def extract_features(words):\n",
    "    return dict([(word, True) for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Number of training datapoints: 1600\n",
      "Number of test datapoints: 400\n",
      "\n",
      "Accuracy of the classifier: 0.735\n",
      "\n",
      "Top 15 most informative words:\n",
      "1. outstanding\n",
      "2. insulting\n",
      "3. vulnerable\n",
      "4. ludicrous\n",
      "5. uninvolving\n",
      "6. astounding\n",
      "7. avoids\n",
      "8. fascination\n",
      "9. seagal\n",
      "10. affecting\n",
      "11. animators\n",
      "12. darker\n",
      "13. anna\n",
      "14. symbol\n",
      "15. idiotic\n",
      "\n",
      "Movie review predictions:\n",
      "\n",
      "Review: The costumes in this movie were great\n",
      "Predicted sentiment: Positive\n",
      "Probability: 0.59\n",
      "\n",
      "Review: I think the story was terrible and the characters were very weak\n",
      "Predicted sentiment: Negative\n",
      "Probability: 0.8\n",
      "\n",
      "Review: People say that the director of the movie is amazing\n",
      "Predicted sentiment: Positive\n",
      "Probability: 0.6\n",
      "\n",
      "Review: This is such an idiotic movie. I will not recommend it to anyone.\n",
      "Predicted sentiment: Negative\n",
      "Probability: 0.87\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    # Load the reviews from the corpus \n",
    "    fileids_pos = movie_reviews.fileids('pos')\n",
    "    fileids_neg = movie_reviews.fileids('neg')\n",
    "     \n",
    "    # Extract the features from the reviews\n",
    "    features_pos = [(extract_features(movie_reviews.words(\n",
    "            fileids=[f])), 'Positive') for f in fileids_pos]\n",
    "    features_neg = [(extract_features(movie_reviews.words(\n",
    "            fileids=[f])), 'Negative') for f in fileids_neg]\n",
    "     \n",
    "    # Define the train and test split (80% and 20%)\n",
    "    threshold = 0.8\n",
    "    num_pos = int(threshold * len(features_pos))\n",
    "    num_neg = int(threshold * len(features_neg))\n",
    "     \n",
    "     # Create training and training datasets\n",
    "    features_train = features_pos[:num_pos] + features_neg[:num_neg]\n",
    "    features_test = features_pos[num_pos:] + features_neg[num_neg:]  \n",
    "\n",
    "    # Print the number of datapoints used\n",
    "    print('\\nNumber of training datapoints:', len(features_train))\n",
    "    print('Number of test datapoints:', len(features_test))\n",
    "     \n",
    "    # Train a Naive Bayes classifier \n",
    "    classifier = NaiveBayesClassifier.train(features_train)\n",
    "    print('\\nAccuracy of the classifier:', nltk_accuracy(\n",
    "            classifier, features_test))\n",
    "\n",
    "    N = 15\n",
    "    print('\\nTop ' + str(N) + ' most informative words:')\n",
    "    for i, item in enumerate(classifier.most_informative_features()):\n",
    "        print(str(i+1) + '. ' + item[0])\n",
    "        if i == N - 1:\n",
    "            break\n",
    "\n",
    "    # Test input movie reviews\n",
    "    input_reviews = [\n",
    "        'The costumes in this movie were great', \n",
    "        'I think the story was terrible and the characters were very weak',\n",
    "        'People say that the director of the movie is amazing', \n",
    "        'This is such an idiotic movie. I will not recommend it to anyone.' \n",
    "    ]\n",
    "\n",
    "    print(\"\\nMovie review predictions:\")\n",
    "    for review in input_reviews:\n",
    "        print(\"\\nReview:\", review)\n",
    "\n",
    "        # Compute the probabilities\n",
    "        probabilities = classifier.prob_classify(extract_features(review.split()))\n",
    "\n",
    "        # Pick the maximum value\n",
    "        predicted_sentiment = probabilities.max()\n",
    "\n",
    "        # Print outputs\n",
    "        print(\"Predicted sentiment:\", predicted_sentiment)\n",
    "        print(\"Probability:\", round(probabilities.prob(predicted_sentiment), 2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}